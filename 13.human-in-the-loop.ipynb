{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "small_llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구글 메일 발송 Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_community import GmailToolkit\n",
    "# from langchain_google_community.gmail.utils import (\n",
    "#     build_resource_service,\n",
    "#     get_gmail_credentials,\n",
    "# )\n",
    "\n",
    "# # Can review scopes here https://developers.google.com/gmail/api/auth/scopes\n",
    "# # For instance, readonly scope is 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "# credentials = get_gmail_credentials(\n",
    "#     token_file=\"./google/token.json\",\n",
    "#     scopes=[\"https://mail.google.com/\"],\n",
    "#     client_secrets_file=\"./google/credentials.json\",\n",
    "# )\n",
    "# api_resource = build_resource_service(credentials=credentials)\n",
    "# gmail_toolkit = GmailToolkit(api_resource=api_resource)\n",
    "# gmail_tool_list = gmail_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArXiv Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "loaded_tool_list = load_tools(\n",
    "    [\"arxiv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name = 'real_estate_tax',\n",
    "    persist_directory = './real_estate_tax_collection'\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"real_estate_tax_retriever\",\n",
    "    description=\"Contains information about real estate tax up to December 2024\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply, search_tool] # + gmail_tool_list\n",
    "tool_list += loaded_tool_list\n",
    "tool_list += [retriever_tool]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply.invoke({\"a\": 3, \"b\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tools.invoke(\"What is 3 plus 5?\")\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node.invoke({\"messages\": [ai_message]}) # list[AnyMessage], 마지막 AIMessage, tool_calls를 포함할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "# 요약하기 위해 오버라이딩\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 메세지 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    summary_prompt = f\"summarize this chat history below: \\n\\nchat_history:{messages}\"\n",
    "    if summary != \"\":\n",
    "        summary_prompt += f'''summarize this chat history below while looking at the summary of earlier conversations\n",
    "chat_history:{messages}\n",
    "summary:{summary}'''\n",
    "    summary = small_llm.invoke(summary_prompt)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'summary': response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def agent(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    if summary != \"\":\n",
    "        messages = [SystemMessage(content=f\"Here is the summary of the earlier conversation: {summary}\")] + messages\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt, Command\n",
    "from typing import Literal\n",
    "\n",
    "def human_review(state: AgentState) -> Command[Literal['tools', 'agent']]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "    human_review = interrupt({\n",
    "        'question': '이렇게 진행하면 될까요?',\n",
    "        'tool_call': tool_call,\n",
    "    })\n",
    "    review_action = human_review['action']\n",
    "    review_data = human_review.get('data', None)\n",
    "    \n",
    "    if review_action == 'continue':\n",
    "        return Command(goto='tools')\n",
    "    \n",
    "    if review_action == 'update_args':\n",
    "        updated_ai_message = {\n",
    "            'id': last_message.id,\n",
    "            'role': 'ai',\n",
    "            'content': last_message.content,\n",
    "            'tool_calls': [{\n",
    "                'id': tool_call['id'],\n",
    "                'name': tool_call['name'],\n",
    "                'args': review_data,\n",
    "            }],\n",
    "        }\n",
    "        return Command(goto='tools', update={'messages': [updated_ai_message]})\n",
    "    \n",
    "    if review_action == 'update_tool':\n",
    "        updated_tool_message = {\n",
    "            'tool_call_id': tool_call['id'],\n",
    "            'name': tool_call['name'],\n",
    "            'role': 'tool',\n",
    "            'content': review_data,\n",
    "        }\n",
    "        return Command(goto='agent', update={'messages': [updated_tool_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node 방식으로 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "def delete_messages(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    delete_messages = [RemoveMessage(id=message.id) for message in messages[:-3]]\n",
    "    return {'messages': delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    last_ai_message = messages[-1]\n",
    "    if last_ai_message.tool_calls:\n",
    "        return 'human_review'\n",
    "    # return 'delete_messages'\n",
    "    return 'summarize_messages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "graph_builder.add_node(human_review)\n",
    "# graph_builder.add_node('delete_messages', delete_messages)\n",
    "graph_builder.add_node(delete_messages) # node 이름과 함수이름이 같으면 생략가능\n",
    "graph_builder.add_node(summarize_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "# graph_builder.add_conditional_edges(\n",
    "#     'agent',\n",
    "#     should_continue,\n",
    "#     ['tools', END],\n",
    "# )\n",
    "## tools_condition를 사용해서 변경\n",
    "# graph_builder.add_conditional_edges(\n",
    "#     'agent',\n",
    "#     tools_condition,\n",
    "# )\n",
    "## delete_message를 사용해서 변경\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['human_review', 'summarize_messages'],\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "graph_builder.add_edge('summarize_messages', 'delete_messages')\n",
    "graph_builder.add_edge('delete_messages', END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'summarize_paper'\n",
    "    }\n",
    "}\n",
    "\n",
    "# query = \"Attention Is All You Need 논문의 내용을 검색해서 요약해주세요\"\n",
    "query = \"LLM Survey 논문의 내용을 검색해서 요약해주세요\"\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage(query)], 'summary':''}, config=config, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in graph.stream(\n",
    "#     Command(resume={'action': 'continue'}), config=config, stream_mode='updates'\n",
    "# ):\n",
    "#     print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in graph.stream(\n",
    "#     Command(resume={'action': 'update_args', 'data':{'query': 'Large Language Model: A Survey'}}), config=config, stream_mode='updates'\n",
    "# ):\n",
    "#     print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    Command(resume={'action': 'update_tool', 'data':'arxiv말고 web에서 검색해주세요'}), config=config, stream_mode='updates'\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    Command(resume={'action': 'continue'}), config=config, stream_mode='updates'\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values['messages']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
