{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "small_llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구글 메일 발송 Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_google_community import GmailToolkit\n",
    "# from langchain_google_community.gmail.utils import (\n",
    "#     build_resource_service,\n",
    "#     get_gmail_credentials,\n",
    "# )\n",
    "\n",
    "# # Can review scopes here https://developers.google.com/gmail/api/auth/scopes\n",
    "# # For instance, readonly scope is 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "# credentials = get_gmail_credentials(\n",
    "#     token_file=\"./google/token.json\",\n",
    "#     scopes=[\"https://mail.google.com/\"],\n",
    "#     client_secrets_file=\"./google/credentials.json\",\n",
    "# )\n",
    "# api_resource = build_resource_service(credentials=credentials)\n",
    "# gmail_toolkit = GmailToolkit(api_resource=api_resource)\n",
    "# gmail_tool_list = gmail_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArXiv Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "loaded_tool_list = load_tools(\n",
    "    [\"arxiv\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name = 'real_estate_tax',\n",
    "    persist_directory = './real_estate_tax_collection'\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"real_estate_tax_retriever\",\n",
    "    description=\"Contains information about real estate tax up to December 2024\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply, search_tool] # + gmail_tool_list\n",
    "tool_list += loaded_tool_list\n",
    "tool_list += [retriever_tool]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply.invoke({\"a\": 3, \"b\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm_with_tools.invoke(\"What is 3 plus 5?\")\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node.invoke({\"messages\": [ai_message]}) # list[AnyMessage], 마지막 AIMessage, tool_calls를 포함할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "# 요약하기 위해 오버라이딩\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 메세지 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    summary_prompt = f\"summarize this chat history below: \\n\\nchat_history:{messages}\"\n",
    "    if summary != \"\":\n",
    "        summary_prompt += f'''summarize this chat history below while looking at the summary of earlier conversations\n",
    "chat_history:{messages}\n",
    "summary:{summary}'''\n",
    "    summary = small_llm.invoke(summary_prompt)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'summary': response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def agent(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    if summary != \"\":\n",
    "        messages = [SystemMessage(content=f\"Here is the summary of the earlier conversation: {summary}\")] + messages\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node 방식으로 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "def delete_messages(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    delete_messages = [RemoveMessage(id=message.id) for message in messages[:-3]]\n",
    "    return {'messages': delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    last_ai_message = messages[-1]\n",
    "    if last_ai_message.tool_calls:\n",
    "        return 'tools'\n",
    "    # return 'delete_messages'\n",
    "    return 'summarize_messages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "# graph_builder.add_node('delete_messages', delete_messages)\n",
    "graph_builder.add_node(delete_messages) # node 이름과 함수이름이 같으면 생략가능\n",
    "graph_builder.add_node(summarize_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "# graph_builder.add_conditional_edges(\n",
    "#     'agent',\n",
    "#     should_continue,\n",
    "#     ['tools', END],\n",
    "# )\n",
    "## tools_condition를 사용해서 변경\n",
    "# graph_builder.add_conditional_edges(\n",
    "#     'agent',\n",
    "#     tools_condition,\n",
    "# )\n",
    "## delete_message를 사용해서 변경\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', 'summarize_messages'],\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "graph_builder.add_edge('summarize_messages', 'delete_messages')\n",
    "graph_builder.add_edge('delete_messages', END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-strerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'paper_summary'\n",
    "    }\n",
    "}\n",
    "\n",
    "# query = \"What currency is in Billy Giles\\' birthplace?\"\n",
    "# query = \"Attention Is All You Need라는 논문을 요약해서 설명해줘.\"\n",
    "# query = \"집이 15억일 때 종합부동산세를 계산해줄 수 있나요?\"\n",
    "query = \"Attention Is All You Need라는 논문을 요약해서 이메일 초안 작성해줘.\"\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage(query)], 'summary':''}, config=config, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_message_list = graph.get_state(config).values['messages']\n",
    "current_message_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최근 하나의 메시지만 남기고 삭제\n",
    "##### 토큰 절약 -> 비용 절약, 시간 절약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import RemoveMessage\n",
    "\n",
    "# for index, message in enumerate(current_message_list):\n",
    "#     if index < len(current_message_list) - 1:\n",
    "#         graph.update_state(config, {'messages': RemoveMessage(id=message.id)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_message_list = graph.get_state(config).values['messages']\n",
    "current_message_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_query = \"논문의 출처 url을 첨부해주세요\"\n",
    "# for chunk in graph.stream({'messages': [HumanMessage(update_query)]}, config=config, stream_mode='values'):\n",
    "#     chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
