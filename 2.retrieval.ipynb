{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `PyPDFLoader`를 사용해 전처리된 데이터를 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_file_path = \"./income_tax.pdf\"\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event loop error debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리를 위한 [py-zerox](https://www.piwheels.org/project/py-zerox/) 패키지를 설치합니다\n",
    "- `py-zerox`를 통해 pdf파일을 전처리합니다\n",
    "- 강의에서는 `OpenAI`를 사용하지만, 아래 예제는 `AzureOpenAI`를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyzerox import zerox\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "### Model Setup (Use only Vision Models) Refer: https://docs.litellm.ai/docs/providers ###\n",
    "\n",
    "## placeholder for additional model kwargs which might be required for some models\n",
    "kwargs = {}\n",
    "\n",
    "## system prompt to use for the vision model\n",
    "custom_system_prompt = None\n",
    "\n",
    "# to override\n",
    "# custom_system_prompt = \"For the below PDF page, do something..something...\" ## example\n",
    "\n",
    "###################### Example for OpenAI ######################\n",
    "model = \"gpt-4o-mini\" ## openai model\n",
    "\n",
    "###################### For other providers refer: https://docs.litellm.ai/docs/providers ######################\n",
    "\n",
    "# Define main async entrypoint\n",
    "async def main():\n",
    "    file_path = \"./income_tax.pdf\" ## local filepath and file URL supported\n",
    "\n",
    "    ## process only some pages or all\n",
    "    select_pages = None ## None for all, but could be int or list(int) page numbers (1 indexed)\n",
    "\n",
    "    output_dir = \"./documents\" ## directory to save the consolidated markdown file\n",
    "    result = await zerox(file_path=file_path, model=model, output_dir=output_dir,\n",
    "                        custom_system_prompt=custom_system_prompt,select_pages=select_pages, concurrency=1, **kwargs)\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# run the main function:\n",
    "result = asyncio.run(main())\n",
    "\n",
    "# print markdown result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zerox를 활용한 전처리 후 생성된 마크다운 파일을 LangGraph에서 활용하기 위해 [unstructured](https://unstructured.io/) 패키지를 설치합니다\n",
    "- `UnstructuredMarkdownLoader`를 사용해 전처리된 데이터를 확인합니다\n",
    "    - `loader`활용 시 테이블 구조가 사라지는 것을 확인할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=100,\n",
    "    separators=['\\n\\n', '\\n']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "markdown_path = \"./documents/income_tax.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마크다운 테이블을 활용하기 위해 `.md` -> `.txt`로 변환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text_path = './documents/income_tax.txt'\n",
    "\n",
    "# 마크다운 파일을 읽어옵니다\n",
    "with open(markdown_path, 'r', encoding='utf-8') as md_file:\n",
    "    md_content = md_file.read()\n",
    "\n",
    "# 마크다운 콘텐츠를 HTML로 변환합니다\n",
    "html_content = markdown.markdown(md_content)\n",
    "\n",
    "# HTML 콘텐츠를 파싱하여 텍스트만 추출합니다\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = soup.get_text()\n",
    "\n",
    "# 추출한 텍스트를 텍스트 파일로 저장합니다\n",
    "with open(text_path, 'w', encoding='utf-8') as txt_file:\n",
    "    txt_file.write(text_content)\n",
    "\n",
    "print(\"Markdown converted to plain text successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `TextLoader`를 사용해 전처리된 데이터를 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "text_path = './documents/income_tax.txt'\n",
    "\n",
    "loader = TextLoader(text_path)\n",
    "document_list = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전처리된 데이터를 벡터화하기 위해 [Chroma](https://docs.trychroma.com/getting-started)를 활용합니다\n",
    "- LangChain과의 호환을 위해 [langchain-chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma/)를 설치합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    embedding=embeddings,\n",
    "    collection_name = 'income_tax_collection',\n",
    "    persist_directory = './income_tax_collection'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '연봉 5천만원 직장인의 소득세는?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `state`를 선언하고 에이전트를 생성합니다\n",
    "- 2.1강에서 진행한 것과 다르게 `messages` 커스텀 변수들을 선언합니다\n",
    "    - `query`는 사용자의 질문을 저장하는 용도로 사용합니다\n",
    "    - `context`는 벡터 스토어에서 추출한 데이터를 저장하는 용도로 사용합니다\n",
    "    - `answer`는 최종 응답을 저장하는 용도로 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `retrieve` 노드는 사용자의 질문을 받아 벡터 스토어에서 추출한 데이터를 반환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 검색된 문서가 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state['query']  # state에서 사용자의 질문을 추출합니다.\n",
    "    docs = retriever.invoke(query)  # 질문과 관련된 문서를 검색합니다.\n",
    "    return {'context': docs}  # 검색된 문서를 포함한 state를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `LangChain`의 `hub`를 통해 미리 정의된 RAG 프롬프트를 활용합니다\n",
    "    - `hub`에는 이미 검증된 프롬프트들이 많기 때문에 프로젝트 진행 시 좋은 시작점이 됩니다\n",
    "    - `hub`에서 프롬프트를 찾아보고, 동작을 확인한 후 커스텀 하는 것을 권장합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문과 검색된 문서를 기반으로 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 검색된 문서를 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 생성된 응답이 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    context = state['context']  # state에서 검색된 문서를 추출합니다.\n",
    "    query = state['query']  # state에서 사용자의 질문을 추출합니다.\n",
    "    rag_chain = prompt | llm  # RAG 프롬프트와 LLM을 연결하여 체인을 만듭니다.\n",
    "    response = rag_chain.invoke({'question': query, 'context': context})  # 질문과 문맥을 사용하여 응답을 생성합니다.\n",
    "    return {'answer': response}  # 생성된 응답을 포함한 state를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node('retrieve', retrieve)\n",
    "graph_builder.add_node('generate', generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'retrieve')\n",
    "graph_builder.add_edge('retrieve', 'generate')\n",
    "graph_builder.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 병렬처리나 `conditional_edge`가 없는 경우 `add_sequence()`를 통해 순차적으로 동작하는 그래프를 생성할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_graph_builder = StateGraph(AgentState).add_sequence([retrieve, generate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_graph_builder.add_edge(START, 'retrieve')\n",
    "sequence_graph_builder.add_edge('generate', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_graph = sequence_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(sequence_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {'query': query}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
