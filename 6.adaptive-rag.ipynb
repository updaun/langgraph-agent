{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: list\n",
    "    answer: str\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    ")\n",
    "\n",
    "def web_search(state: AgentState):\n",
    "    query = state['query']\n",
    "    results = tavily_search_tool.invoke(query)\n",
    "    print(f'web search results == {results}')\n",
    "    return {'context': results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "generate_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def web_generate(state: AgentState):\n",
    "    context = state['context'] \n",
    "    query = state['query']  \n",
    "    rag_chain = generate_prompt | generate_llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({'question': query, 'context': context}) \n",
    "    return {'answer': response} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "basic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def basic_generate(state: AgentState):\n",
    "    query = state['query']\n",
    "    basic_llm_chain = basic_llm | StrOutputParser()\n",
    "    response = basic_llm_chain.invoke(query)\n",
    "    return {'answer': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class Route(BaseModel):\n",
    "    target: Literal['vector_store', 'llm', 'web_search'] = Field(\n",
    "        description=\"The target for the query to answer\"\n",
    "    )\n",
    "\n",
    "router_system_prompt = \"\"\"\n",
    "you are an expert at routing a user's question to 'vector_store', 'llm' or 'web_search'\n",
    "'vector_store' contains information about income tax up to December 2024.\n",
    "if you think the question is simple enough use 'llm'\n",
    "if you think you need to search the web to answer the question use 'web_search'\n",
    "\"\"\"\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', router_system_prompt),\n",
    "    ('user', '{query}'),\n",
    "])\n",
    "\n",
    "router_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "structured_router_llm = router_llm.with_structured_output(Route)\n",
    "\n",
    "def router(state: AgentState):\n",
    "    query = state['query']\n",
    "    router_chain = router_prompt | structured_router_llm\n",
    "    route = router_chain.invoke({'query': query})\n",
    "    print(f'router route == {route}')\n",
    "    print(f'route.target == {route.target}')\n",
    "    return route.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from income_tax_graph import graph as income_tax_subgraph\n",
    "\n",
    "graph_builder.add_node('income_tax_agent', income_tax_subgraph)\n",
    "graph_builder.add_node('web_search', web_search)\n",
    "graph_builder.add_node('web_generate', web_generate)\n",
    "graph_builder.add_node('basic_generate', basic_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    START,\n",
    "    router,\n",
    "    {\n",
    "        'vector_store': 'income_tax_agent',\n",
    "        'llm': 'basic_generate',\n",
    "        'web_search': 'web_search'\n",
    "    }\n",
    ")\n",
    "\n",
    "graph_builder.add_edge('web_search', 'web_generate')\n",
    "graph_builder.add_edge('web_generate', END)\n",
    "graph_builder.add_edge('basic_generate', END)\n",
    "graph_builder.add_edge('income_tax_agent', END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "# import nest_asyncio\n",
    "\n",
    "# nest_asyncio.apply() \n",
    "\n",
    "# display(\n",
    "#     Image(\n",
    "#         graph.get_graph().draw_mermaid_png(\n",
    "#             curve_style=CurveStyle.LINEAR,\n",
    "#             node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
    "#             wrap_label_n_words=9,\n",
    "#             output_file_path=None,\n",
    "#             draw_method=MermaidDrawMethod.PYPPETEER,\n",
    "#             background_color=\"white\",\n",
    "#             padding=10,\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 관련 질문\n",
    "initial_state = {\n",
    "    'query' : '거주자의 연봉이 5천만원일 때 소득세는 얼마인가요?'\n",
    "}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 질문\n",
    "initial_state = {\n",
    "    'query' : '대한민국 수도는'\n",
    "}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹검색\n",
    "initial_state = {\n",
    "    'query' : '역삼 맛집 추천해주세요'\n",
    "}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
