{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "small_llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.agent_toolkits.polygon.toolkit import PolygonToolkit\n",
    "from langchain_community.utilities.polygon import PolygonAPIWrapper\n",
    "\n",
    "polygon = PolygonAPIWrapper()\n",
    "toolkit = PolygonToolkit.from_polygon_api_wrapper(polygon)\n",
    "polygon_tools = toolkit.get_tools()\n",
    "\n",
    "market_research_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[YahooFinanceNewsTool()] + polygon_tools,\n",
    "    state_modifier=\"You are a market researcher. Provide fact only not opinions.\",\n",
    ")\n",
    "\n",
    "def market_research_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = market_research_agent.invoke(state)\n",
    "    # print(f\"marget research result: {result}\")\n",
    "    return Command(\n",
    "        update={'messages': [HumanMessage(content=result['messages'][-1].content, name='market_research')]},\n",
    "        goto='supervisor',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_stock_price(ticker: str) -> str:\n",
    "    \"\"\"Given a stock ticker, return the price data for the past month\"\"\"\n",
    "    stock_info = yf.download(ticker, period='1mo').to_dict()\n",
    "    return stock_info\n",
    "\n",
    "\n",
    "stock_research_tools = [get_stock_price]\n",
    "stock_research_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=stock_research_tools,\n",
    "    state_modifier=\"You are a stock researcher. Provide fact only not opinions.\",\n",
    ")\n",
    "\n",
    "\n",
    "def stock_research_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = stock_research_agent.invoke(state)\n",
    "    # print(f\"stock research result: {result}\")\n",
    "    return Command(\n",
    "        update={'messages': [HumanMessage(content=result['messages'][-1].content, name='stock_research')]},\n",
    "        goto='supervisor',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def company_research_tool(ticker: str) -> dict:\n",
    "    \"\"\"Given a ticker, return the financial information and SEC filings\"\"\"\n",
    "    company_info = yf.Ticker(ticker)\n",
    "    financial_info = company_info.get_financials()\n",
    "    sec_filings = company_info.get_sec_filings()\n",
    "    return {\n",
    "        'financial_info': financial_info,\n",
    "        'sec_filings': sec_filings,\n",
    "    }\n",
    "\n",
    "company_research_tools = [company_research_tool]\n",
    "company_research_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=company_research_tools,\n",
    "    state_modifier=\"You are a company researcher. Provide fact only not opinions.\",\n",
    ")\n",
    "\n",
    "def company_research_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = company_research_agent.invoke(state)\n",
    "    # print(f\"company research result: {result}\")\n",
    "    return Command(\n",
    "        update={'messages': [HumanMessage(content=result['messages'][-1].content, name='company_research')]},\n",
    "        goto='supervisor',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "analyst_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a stock market analyst. Given the following information,\n",
    "Please decide whether to buy, sell, or hold the stock.\n",
    "\n",
    "Information:\n",
    "{messages}\"\"\",\n",
    ")\n",
    "\n",
    "analyst_chain = analyst_prompt | llm\n",
    "\n",
    "def analyst_node(state: MessagesState):\n",
    "    result = analyst_chain.invoke({'messages': state['messages'][1:]})\n",
    "    # return {'messages': [HumanMessage(content=result.content, name='analyst')]}\n",
    "    return {'messages': [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "members = [\"market_research\", \"stock_research\", \"company_research\"]\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def supervisor_node(state: State) -> Command[Literal[*members, \"analyst\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = \"analyst\"\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "graph_builder.add_node(\"supervisor\", supervisor_node)\n",
    "graph_builder.add_node(\"market_research\", market_research_node)\n",
    "graph_builder.add_node(\"stock_research\", stock_research_node)\n",
    "graph_builder.add_node(\"company_research\", company_research_node)\n",
    "graph_builder.add_node(\"analyst\", analyst_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"supervisor\")\n",
    "graph_builder.add_edge(\"analyst\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Would you invest in Snowflake?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
